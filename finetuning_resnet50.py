# -*- coding: utf-8 -*-
"""FineTuning_Resnet50.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pw7WLNU4HcEwLd_jiCQWc7hwGznR3LZe

# Initialisation
"""

import kagglehub
yash92328_ai4mars_terrainaware_autonomous_driving_on_mars_path = kagglehub.dataset_download('yash92328/ai4mars-terrainaware-autonomous-driving-on-mars')
print('Data source imported to path:', yash92328_ai4mars_terrainaware_autonomous_driving_on_mars_path)

print('Data source import complete.')

#!pip install -q pytorch-lightning torchmetrics wandb
import sys
sys.path.append("./docker-python/patches")
import os
import random
from typing import List, Tuple
import time

import cv2
import matplotlib.pyplot as plt
import numpy as np
import pytorch_lightning as pl
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import wandb
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.loggers import WandbLogger
from sklearn.metrics import accuracy_score, confusion_matrix, jaccard_score
from sklearn.model_selection import KFold
from torch.utils.data import DataLoader, Dataset, random_split
from torchmetrics import Accuracy, ConfusionMatrix, JaccardIndex
from torchvision import transforms
from torchvision.transforms import transforms
from tqdm import tqdm


# Log into Wandb
!wandb login 8f5e59d11057e90cd7c036f1694b2ee842b7e03e
device='cuda' if torch.cuda.is_available() else 'cpu'

from google.colab import drive
drive.mount('/gdrive')
project_path = "/gdrive/My Drive/Colab Notebooks"

"""# Functions

"""

#========Imported function and classes
class AI4MARSDataset(Dataset):
    def __init__(self, images_path: str, masks_path: str, dataset_size: int = 500):
        self.images_path = images_path
        self.masks_path = masks_path
        self.dataset_size = dataset_size

        images = set(os.listdir(images_path))
        self.masks = [mask for mask in os.listdir(masks_path) if mask[:-4] + ".JPG" in images][:dataset_size]

    def __len__(self):
        return len(self.masks)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        mask_name = self.masks[idx]

        image_path = os.path.join(self.images_path, mask_name[:-4] + ".JPG")
        image = cv2.imread(image_path)
        image = cv2.resize(image, (224, 224))
        image = np.asarray(image, dtype=np.float32) / 255.0
        image = np.transpose(image, (2, 0, 1))  # Change the order of dimensions to (C, H, W)
        image = torch.from_numpy(image)

        mask_path = os.path.join(self.masks_path, mask_name)
        mask = cv2.imread(mask_path, 0)
        mask = cv2.resize(mask, (224, 224), interpolation=cv2.INTER_NEAREST)
        mask = np.array(mask, dtype=np.uint8)
        mask[mask == 255] = 4
        mask = torch.from_numpy(mask)
        mask = mask.long()

        return image, mask

class AI4MARSDataModule(pl.LightningDataModule):
    def __init__(self, images_path: str, masks_path: str, dataset_size: int = 5000, batch_size: int = 32, num_workers: int = 0):
        super().__init__()
        self.images_path = images_path
        self.masks_path = masks_path
        self.dataset_size = dataset_size
        self.batch_size = batch_size
        self.num_workers = num_workers

    def setup(self, stage=None):
      full = AI4MARSDataset(self.images_path, self.masks_path, self.dataset_size)
      train_len = int(len(full) * 0.85)
      val_len   = len(full) - train_len
      self.train_ds, self.val_ds = random_split(full, [train_len, val_len])

    def train_dataloader(self):
        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True, pin_memory=True)

    def val_dataloader(self):
        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False, pin_memory=True)

class ImageSegmentationModel(pl.LightningModule):
    def __init__(self, num_classes: int = 5, learning_rate: float = 1e-4):
        super().__init__()

        self.save_hyperparameters()
        self.learning_rate = learning_rate
        self.num_classes = num_classes

        self.model_weights = torchvision.models.segmentation.FCN_ResNet50_Weights.DEFAULT
        self.model = torchvision.models.segmentation.fcn_resnet50(weights=self.model_weights)
        self.model.classifier[-1] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))

        self.loss = nn.CrossEntropyLoss()
        self.confusion_matrix = ConfusionMatrix(task='multiclass', num_classes=num_classes)
        self.accuracy = Accuracy(task='multiclass', num_classes=num_classes)
        self.iou = JaccardIndex(task='multiclass', num_classes=num_classes)

    def forward(self, x):
        return self.model(x)['out']

    def configure_optimizers(self):
        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)
        return optimizer

    def training_step(self, batch, batch_idx):
        x, y = batch
        preds = self(x)
        loss = self.loss(preds, y)
        self.log('train_loss', loss)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        preds = self(x)
        loss = self.loss(preds, y)
        preds = torch.argmax(preds, dim=1)

        # Log metrics
        self.log('val_loss', loss, on_step=True, on_epoch=True)
        self.log('val_acc', self.accuracy(preds, y), on_step=True, on_epoch=True)
        self.log('val_iou', self.iou(preds, y), on_step=True, on_epoch=True)

# function coded from scratch
def custom_freeze(self, n: int, freeze_bn):
    total_layers=[]
    for name, _ in self.model.named_parameters():
        total_layers.append(name)
    unfreeze_classifier=1 if -n!=0 else 0

    n-=1# minus the classifier layer
    # print("inters ",(-n)*3-unfreeze_classifier*5-5)
    layers_to_unfreeze=total_layers[(-n)*3-unfreeze_classifier*5-5:-5]  # Get the last n layers to unfreeze, if -2, unfreeze the last layer
    print("Layers to unfreeze:", layers_to_unfreeze)
    # 3=conv+bn1+bn2
    # +5=classifier0,1,4
    # :5=aux
    for name, param in self.model.named_parameters():
        # If any key in the list matches the parameter name → unfreeze
        if any(key in name for key in layers_to_unfreeze):
            param.requires_grad = True
            # 如果冻结BN层，则只冻结在 layers_to_unfreeze 中的 BN 层
            if freeze_bn and ('bn' in name or 'downsample.1' in name):
                if any(key in name for key in layers_to_unfreeze):  # 保证只有在解冻的层内冻结BN
                    param.requires_grad = True
                else:
                    param.requires_grad = False
        else:
            param.requires_grad = False
        # Always freeze BatchNorm if requested
        # for detailed structure see the pic at https://zhuanlan.zhihu.com/p/353235794
     # Print for verify
    print("\nTrainable params (requires_grad=True)/////////////////////////////////////////////////////////////////////////:")
    for name, param in self.model.named_parameters():
        if param.requires_grad:
            print("  •", name)

def train_model(model: ImageSegmentationModel, data_module: AI4MARSDataModule, freeze_to, epochs: int = 5):
    wandb_logger = pl.loggers.WandbLogger(name="AI4MARS_run", project="AI4MARS")
    ckpt_cb = ModelCheckpoint(
        monitor="val_loss",
        dirpath="checkpoints",
        filename="best-{epoch:02d}-{val_loss:.4f}",
        save_top_k=1,
        mode="min",
    )

    trainer = pl.Trainer(
        max_epochs=epochs,
        accelerator="gpu",
        devices=1,
        logger=wandb_logger,
        callbacks=[ckpt_cb],
        log_every_n_steps=50,
    )

    # train
    trainer.fit(model, data_module)

    # Save
    out_path = os.path.join(project_path, f"weit_{freeze_to}_unfreezed.pth")
    torch.save(model.state_dict(), out_path)
    print("Model saved at:", out_path)
    return out_path

"""# Load Data and Model"""

# Paths
base = yash92328_ai4mars_terrainaware_autonomous_driving_on_mars_path \
    + "/ai4mars-dataset-merged-0.1/msl"

images_path = os.path.join(base, "images/edr")
masks_path  = os.path.join(base, "labels/train")
IMAGES_PATH = os.path.join(base, "images/edr")
MASK_PATH_TRAIN = os.path.join(base, "labels/train")
MASK_PATH_TEST = os.path.join(base, "labels/test/masked-gold-min3-100agree")

# Hyperparams
DATASET_SIZE = 1000
BATCH_SIZE   = 30
EPOCHS       = 10

# DataModule
rock_data = AI4MARSDataModule(
    IMAGES_PATH, MASK_PATH_TRAIN,
    dataset_size=DATASET_SIZE,
    batch_size=BATCH_SIZE,
    num_workers=2,
)
rock_data.setup()

"""#Training

"""

# Model + pre-trained weights + freezing
import time
tr_time=[]

#freezeing settings
#freeze_to = 1
freeze_bn = False
layers2freeze=[1,2,3,4,5,7,10,15,25,30,40]
for freeze_to in layers2freeze:
  #load model
  model = ImageSegmentationModel()
  model.load_state_dict(torch.load(os.path.join(project_path, "weit_COCO.pth"))) # weights initialised with COCO

  #Freeze/Unfreeze layers
  custom_freeze(model, freeze_to, freeze_bn)

  if freeze_to!=0:
    #Training
    start_time = time.time()
    train_model(model, rock_data, freeze_to, epochs=EPOCHS)
    end_time = time.time()
    print(f"Training time for {freeze_to} layers: {end_time - start_time} seconds")
    tr_time.append(end_time - start_time)

print(tr_time)

"""# Evaluation"""

############################################# EVALUATION #######################
# Preprocess images
def preprocess_image(image_path: str, return_tensor: bool = False):
    image = cv2.imread(image_path)
    image = cv2.resize(image, (224, 224))
    image_normalized = np.asarray(image, dtype=np.float32) / 255.0

    if return_tensor:
        image_normalized = np.transpose(image_normalized, (2, 0, 1))
        image_tensor = torch.from_numpy(image_normalized).unsqueeze(0)
        return image, image_tensor

    return image

# Preprocess masks
def preprocess_mask(mask_path: str):
    mask = cv2.imread(mask_path, 0)
    mask = cv2.resize(mask, (224, 224), interpolation=cv2.INTER_NEAREST)
    mask[mask == 255] = 4
    return mask

class TestDataset(Dataset):
    def __init__(self, images_path: str, masks_path: str):
        self.images_path = images_path
        self.masks_path = masks_path
        self.mask_files = [mask for mask in os.listdir(masks_path) if mask.endswith("_merged.png")]

    def __len__(self):
        return len(self.mask_files)

    def __getitem__(self, idx):
        mask_name = self.mask_files[idx]
        image_name = mask_name[:-11] + ".JPG"

        image_path = os.path.join(self.images_path, image_name)
        _, image_tensor = preprocess_image(image_path, return_tensor=True)

        mask_path = os.path.join(self.masks_path, mask_name)
        mask = preprocess_mask(mask_path)

        # Remove the extra dimension
        image_tensor = image_tensor.squeeze(0)


        return image_tensor, mask

def evaluate_model(model, test_dataloader):
  # Initialize arrays for storing ground truth and predictions
  ground_truths = []
  predictions = []

  for batch_images, batch_masks in tqdm(test_dataloader):
      # Move the images to the GPU
      batch_images = batch_images.to(device)

      # Perform prediction
      with torch.no_grad():
          batch_prediction = model(batch_images)
          batch_predicted_masks = torch.argmax(batch_prediction, dim=1).cpu().numpy()

      # Flatten and append the ground truth and predictions
      ground_truths.extend([mask.flatten() for mask in batch_masks])
      predictions.extend([mask.flatten() for mask in batch_predicted_masks])

  # Compute accuracy and IoU
  accuracy = accuracy_score(np.concatenate(ground_truths), np.concatenate(predictions))
  iou = jaccard_score(np.concatenate(ground_truths), np.concatenate(predictions), average="weighted")
  return accuracy, iou

# Trained Model
#freezed_layers=2
model = ImageSegmentationModel()
layers2freeze=[1,2,3,4,5,7,10,15,25,30,40]

# Load dataloaders
test_dataset = TestDataset(IMAGES_PATH, MASK_PATH_TEST)
test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)

acc=[]
IoU=[]

for freezed_layers in layers2freeze:
  if freezed_layers !=0:
    trained_model_path = os.path.join(project_path, f"weit_{freezed_layers}_unfreezed.pth")
  model.load_state_dict(torch.load(trained_model_path))
  model.eval()
  model.to(device)
  a, I = evaluate_model(model, test_dataloader)
  acc.append(a)
  IoU.append(I)
print(f"Accuracy: {acc}")
print(f"IoU: {IoU}")