# -*- coding: utf-8 -*-
"""MASKEDFineTuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ux8IiSnHRTGW3hVeuTTgXU_DlYX4jQ0K

# Initialisation
"""

import kagglehub
yash92328_ai4mars_terrainaware_autonomous_driving_on_mars_path = kagglehub.dataset_download('yash92328/ai4mars-terrainaware-autonomous-driving-on-mars')
print('Data source imported to path:', yash92328_ai4mars_terrainaware_autonomous_driving_on_mars_path)

print('Data source import complete.')

!pip install -q pytorch-lightning torchmetrics wandb
import sys
sys.path.append("./docker-python/patches")
import os
import random
from typing import List, Tuple
import time

import cv2
import matplotlib.pyplot as plt
import numpy as np
import pytorch_lightning as pl
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import wandb
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.loggers import WandbLogger
from sklearn.metrics import accuracy_score, confusion_matrix, jaccard_score
from sklearn.model_selection import KFold
from torch.utils.data import DataLoader, Dataset, random_split
from torchmetrics import Accuracy, ConfusionMatrix, JaccardIndex
from torchvision import transforms
from torchvision.transforms import transforms
from tqdm import tqdm


# Log into Wandb
!wandb login 8f5e59d11057e90cd7c036f1694b2ee842b7e03e
device='cuda' if torch.cuda.is_available() else 'cpu'

from google.colab import drive
drive.mount('/gdrive')
project_path = "/gdrive/My Drive/Colab Notebooks"

"""# Functions

"""

#========Imported function and classes
class AI4MARSDataset(Dataset):
    def __init__(self, images_path: str, masks_path: str, dataset_size: int = 500):
        self.images_path = images_path
        self.masks_path = masks_path
        self.dataset_size = dataset_size

        images = set(os.listdir(images_path))
        self.masks = [mask for mask in os.listdir(masks_path) if mask[:-4] + ".JPG" in images][:dataset_size]

    def __len__(self):
        return len(self.masks)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        mask_name = self.masks[idx]

        image_path = os.path.join(self.images_path, mask_name[:-4] + ".JPG")
        image = cv2.imread(image_path)
        image = cv2.resize(image, (224, 224))
        image = np.asarray(image, dtype=np.float32) / 255.0
        image = np.transpose(image, (2, 0, 1))  # Change the order of dimensions to (C, H, W)
        image = torch.from_numpy(image)

        mask_path = os.path.join(self.masks_path, mask_name)
        mask = cv2.imread(mask_path, 0)
        mask = cv2.resize(mask, (224, 224), interpolation=cv2.INTER_NEAREST)
        mask = np.array(mask, dtype=np.uint8)
        mask[mask == 255] = 4
        mask = torch.from_numpy(mask)
        mask = mask.long()

        return image, mask

class AI4MARSDataModule(pl.LightningDataModule):
    def __init__(self, images_path: str, masks_path: str, dataset_size: int = 5000, batch_size: int = 32, num_workers: int = 0):
        super().__init__()
        self.images_path = images_path
        self.masks_path = masks_path
        self.dataset_size = dataset_size
        self.batch_size = batch_size
        self.num_workers = num_workers

    def setup(self, stage=None):
        full = AI4MARSDataset(self.images_path, self.masks_path, self.dataset_size)
        train_len = int(len(full) * 0.85)
        val_len   = len(full) - train_len
        self.train_ds, self.val_ds = random_split(full, [train_len, val_len])

    def train_dataloader(self):
        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True, pin_memory=True)

    def val_dataloader(self):
        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True, pin_memory=True)

class ImageSegmentationModel(pl.LightningModule):
    def __init__(self, num_classes: int = 5, learning_rate: float = 1e-4):
        super().__init__()

        self.save_hyperparameters()
        self.learning_rate = learning_rate
        self.num_classes = num_classes

        self.model_weights = torchvision.models.segmentation.FCN_ResNet50_Weights.DEFAULT
        self.model = torchvision.models.segmentation.fcn_resnet50(weights=self.model_weights)
        self.model.classifier[-1] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))

        self.loss = nn.CrossEntropyLoss()
        self.confusion_matrix = ConfusionMatrix(task='multiclass', num_classes=num_classes)
        self.accuracy = Accuracy(task='multiclass', num_classes=num_classes)
        self.iou = JaccardIndex(task='multiclass', num_classes=num_classes)

    def forward(self, x):
        return self.model(x)['out']

    def configure_optimizers(self):
        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)
        return optimizer

    def training_step(self, batch, batch_idx):
        x, y = batch
        preds = self(x)
        loss = self.loss(preds, y)
        self.log('train_loss', loss)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        preds = self(x)
        loss = self.loss(preds, y)
        preds = torch.argmax(preds, dim=1)

        # Log metrics
        self.log('val_loss', loss, on_step=True, on_epoch=True)
        self.log('val_acc', self.accuracy(preds, y), on_step=True, on_epoch=True)
        self.log('val_iou', self.iou(preds, y), on_step=True, on_epoch=True)

def SCLoss(z, label, tau):
    P = z.size(0)
    simil = (z@z.t())/tau
    # remove i=j (put diag to -inf so exp(-inf)=0)
    diag_mask = torch.eye(P, device=simil.device).bool()
    simil = simil.masked_fill(diag_mask, -float('inf'))

    #exp
    exp_simil = torch.exp(simil)

    # find two different element with same label
    is_pos = label.unsqueeze(1) == label.unsqueeze(0)
    # remove if the two element are the same
    is_pos.fill_diagonal_(False)

    loss = 0.0
    for i in range(P):
        # numerator
        pos_sum = exp_simil[i][is_pos[i]].sum()
        # denominator
        tot_sum = exp_simil[i].sum()
        #compute loss
        loss += -torch.log(pos_sum / tot_sum + 1e-12)    # sum for not having zero at num
        loss /= P
    return loss


def compute_SCL_grads(model, SCL_dataloader):
  #initially all grads must be zero for evaluation
  model.zero_grad()

  #extract a batch and move it on cuda
  batch_img, batch_mask = next(iter(SCL_dataloader))
  batch_img=batch_img.to(device)
  batch_mask=batch_mask.to(device)

  #forward step
  SCL_output = model.model.backbone(batch_img)['out']

  # normaliize and reshape
  SCL_output = nn.functional.normalize(SCL_output, dim=1)
  B, C, H, W = SCL_output.shape #batch size, channels, height/8, width/8

  #unadersample pixel per image since not enough gpu memory
  us_px_idx = torch.randperm(H*W, device=SCL_output.device)[:512] #take 512 random pixel (the same for each feature map)
  SCL_output_flat = SCL_output.view(B, C, -1)
  SL_z = SCL_output_flat[:,:,us_px_idx].permute(0,2,1).reshape(-1, C)
  labels_flat = batch_mask.view(B, -1)
  labels = labels_flat[:, us_px_idx].reshape(-1)

  # compute SCL and backward
  temperature = 0.1
  SCL = SCLoss(SL_z, labels, temperature)
  # update model.model.backbone.parameters().grad
  SCL.backward()

def get_mask(model, perc2update):
  conn_mask = {}

  for name, param in model.model.backbone.named_parameters():
    #get gradients for each params (ex module.backbone.layer1.conv1.weights) --> tensor with all the gradients of the layer
    gradient = param.grad
    if gradient is None:
      continue

    gradient = gradient.abs()

    #get number of neurons
    neurons_num = gradient.shape[0]

    # num of connection for each neuron
    conn_num = gradient.numel() // neurons_num

    #select num of connections (at least one)
    K = max(1, int(perc2update * conn_num))

    #reshape
    gradient_flat = gradient.view(neurons_num, -1)

    conn2keep = torch.zeros_like(gradient_flat)

    #save pos of the top K connections
    for i in range(neurons_num):
        topk_idx = torch.topk(gradient_flat[i], K).indices
        conn2keep[i, topk_idx] = 1

    #reashape to original
    conn_mask[name] =  conn2keep.view_as(gradient)

  return conn_mask

def train_model_masked(model, dataloader, dataloader_valid, conn_mask, alpha, project_path, epochs=5):
  model.train()
  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
  n = len(dataloader)

  for epoch in range(epochs):
      epoch_loss = 0.0
      for batch in dataloader:
          img_train, mask_train = batch
          img_train= img_train.to(device)
          mask_train= mask_train.to(device)

          optimizer.zero_grad()

          #forward step
          prediction = model(img_train)
          loss = nn.CrossEntropyLoss()(prediction, mask_train)

          #backward
          loss.backward()

          #Apply mask for masked fine tuning
          for name, param in model.model.backbone.named_parameters():
            if param.grad is not None and name in conn_mask:
              param.grad.mul_(conn_mask[name])

          #compute new weights
          optimizer.step()

          epoch_loss += loss.item()

      final_loss = epoch_loss / n

      #validation for each epoch
      model.eval()
      acc_val=0.0
      loss_val=0.0
      n_val = len(dataloader_valid)

      with torch.no_grad():
        for batch_val in dataloader_valid:
          img_val, mask_val = batch_val
          img_val = img_val.to(device)
          mask_val = mask_val.to(device)

          #forward
          val_preds = model(img_val)
          l_val=nn.CrossEntropyLoss()(val_preds, mask_val).item()

          #get metrics
          val_preds = torch.argmax(val_preds, dim=1)
          acc_val += (val_preds == mask_val).float().mean().item()
          loss_val += l_val

      epoch_val_acc = acc_val / n_val
      epoch_val_loss = loss_val / n_val

      print(f"Epoch {epoch+1}: train_loss = {final_loss:.4f}, valid_loss= {epoch_val_loss:.4f}, valid_acc = {epoch_val_acc:.4f}")

      #call-backs --> checkpoint (keep model with lowest val_loss)
      lowest_val_loss =float('inf')
      if epoch_val_loss < lowest_val_loss:
        lowest_val_loss = epoch_val_loss
        #save
        out_path = os.path.join(project_path, f"MaskedFineTuning_{alpha}.pth")
        torch.save(model.state_dict(), out_path)
      model.train()
  print("Model saved at:", out_path)

"""# Load Data and Model"""

# Paths
base = yash92328_ai4mars_terrainaware_autonomous_driving_on_mars_path \
    + "/ai4mars-dataset-merged-0.1/msl"

images_path = os.path.join(base, "images/edr")
masks_path  = os.path.join(base, "labels/train")
IMAGES_PATH = os.path.join(base, "images/edr")
MASK_PATH_TRAIN = os.path.join(base, "labels/train")
MASK_PATH_TEST = os.path.join(base, "labels/test/masked-gold-min3-100agree")

# Hyperparams
DATASET_SIZE = 1000
BATCH_SIZE   = 30
EPOCHS       = 10

# DataModule
rock_data = AI4MARSDataModule(
    IMAGES_PATH, MASK_PATH_TRAIN,
    dataset_size=DATASET_SIZE,
    batch_size=BATCH_SIZE,
    num_workers=2,
)
rock_data.setup()

"""#Training

**Gradient-based parameter selection**
"""

# Model + pre-trained weights + freezing
model = ImageSegmentationModel()
model.load_state_dict(torch.load(os.path.join(project_path, "weit_COCO.pth")))

# remove head (it is initilaise randomly so we will train all it)---> change with smaller head just for the SC Loss computation
model.model.classifier=nn.Conv2d(2048, 512, kernel_size=1)
model.model.classifier1=nn.Conv2d(512, 128, kernel_size=1)
model.model.aux_classifier=nn.Identity()

#set training
model.model.backbone.train()
model.to(device)

# check
for name, module in model.named_modules():
  if "classifier" in name:
    print(name, module)
"""
tryed to just remove the classifier head (with Identity()) but so the output is too big and is not possible to process the images,
so add smalller head for reduce dimensions
"""

#============INITIAL GRADIENT COMPUTATION WITH SCL
#upload dataloader for compute SCLoss
BATCH_SIZE=30
SCL_dataloader = DataLoader(rock_data.train_ds, batch_size=BATCH_SIZE, num_workers=2, shuffle=True, pin_memory=True)  #do not need validation set here

compute_SCL_grads(model, SCL_dataloader)

#check (print each layer with mean gradient)
for name, p in model.model.backbone.named_parameters():
    if p.grad is not None:
        print(name, p.grad.abs().mean().item())

"""
Our experiments have shown that with this idea, the majority of the selected
 parameters are located in the top layers of the network
"""

# see which layers have the biggest gradients
grad_stats = []
for name, p in model.model.backbone.named_parameters():
    if p.grad is not None:
        mean_abs = p.grad.abs().mean().item()
        grad_stats.append((name, mean_abs))

grad_stats.sort(key=lambda x: x[1], reverse=True)

# print firsts ten layers
for name, mean_abs in grad_stats[:10]:
    print(f"{name}: {mean_abs:.6f}")

"""Create Maks"""

# ========= MASK FOR TRAIN ONLY NEURONS WITH BIGGEST GRAD
alpha=0.5     # % params for each neuron to train

conn_mask= get_mask(model, alpha)

"""Maked fine Tuning"""

#================== MASKED TRAINING
#load original model (initial weights are the same + i have the original classifier head)
model = ImageSegmentationModel()
model.load_state_dict(torch.load(os.path.join(project_path, "weit_COCO.pth")))
model=model.to(device)

#unfreeze all the model parameters
for param in model.parameters():
  param.requires_grad = True

MFT_Dataloader=DataLoader(rock_data.train_ds, batch_size=BATCH_SIZE, num_workers=2, shuffle=True, pin_memory=True)
MFT_Dataloader_valid = DataLoader(rock_data.val_ds, batch_size=BATCH_SIZE,  num_workers=2, shuffle=False, pin_memory=True)


#train
time_start = time.time()
train_model_masked(model, MFT_Dataloader, MFT_Dataloader_valid, conn_mask, alpha, project_path, epochs=EPOCHS)
time_end = time.time()
print(f"Time taken: {time_end - time_start:.2f} seconds")

#save
out_path = os.path.join(project_path, f"MaskedFineTuning_{alpha}.pth")
torch.save(model.state_dict(), out_path)
print("Model saved at:", out_path)

"""# Evaluation"""

#################################################EVALUATION#####################
# Preprocess images
def preprocess_image(image_path: str, return_tensor: bool = False):
    image = cv2.imread(image_path)
    image = cv2.resize(image, (224, 224))
    image_normalized = np.asarray(image, dtype=np.float32) / 255.0

    if return_tensor:
        image_normalized = np.transpose(image_normalized, (2, 0, 1))
        image_tensor = torch.from_numpy(image_normalized).unsqueeze(0)
        return image, image_tensor

    return image

# Preprocess masks
def preprocess_mask(mask_path: str):
    mask = cv2.imread(mask_path, 0)
    mask = cv2.resize(mask, (224, 224), interpolation=cv2.INTER_NEAREST)
    mask[mask == 255] = 4
    return mask

class TestDataset(Dataset):
    def __init__(self, images_path: str, masks_path: str):
        self.images_path = images_path
        self.masks_path = masks_path
        self.mask_files = [mask for mask in os.listdir(masks_path) if mask.endswith("_merged.png")]

    def __len__(self):
        return len(self.mask_files)

    def __getitem__(self, idx):
        mask_name = self.mask_files[idx]
        image_name = mask_name[:-11] + ".JPG"

        image_path = os.path.join(self.images_path, image_name)
        _, image_tensor = preprocess_image(image_path, return_tensor=True)

        mask_path = os.path.join(self.masks_path, mask_name)
        mask = preprocess_mask(mask_path)

        # Remove the extra dimension
        image_tensor = image_tensor.squeeze(0)


        return image_tensor, mask

def evaluate_model(model, test_dataloader):
  # Initialize arrays for storing ground truth and predictions
  ground_truths = []
  predictions = []

  for batch_images, batch_masks in tqdm(test_dataloader):
      # Move the images to the GPU
      batch_images = batch_images.to(device)

      # Perform prediction
      with torch.no_grad():
          batch_prediction = model(batch_images)
          batch_predicted_masks = torch.argmax(batch_prediction, dim=1).cpu().numpy()

      # Flatten and append the ground truth and predictions
      ground_truths.extend([mask.flatten() for mask in batch_masks])
      predictions.extend([mask.flatten() for mask in batch_predicted_masks])

  # Compute accuracy and IoU
  accuracy = accuracy_score(np.concatenate(ground_truths), np.concatenate(predictions))
  iou = jaccard_score(np.concatenate(ground_truths), np.concatenate(predictions), average="weighted")
  return accuracy, iou

# Trained Model
model = ImageSegmentationModel()
net2test=["001","01","05","10","20","50"]

# Load dataloaders
test_dataset = TestDataset(IMAGES_PATH, MASK_PATH_TEST)
test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)

acc=[]
IoU=[]

for net in net2test:
  trained_model_path = os.path.join(project_path, f"MaskedFineTuning_{net}.pth")
  model.load_state_dict(torch.load(trained_model_path))
  model.eval()
  model.to(device)
  a, I = evaluate_model(model, test_dataloader)
  acc.append(a)
  IoU.append(I)
print(f"Accuracy: {acc}")
print(f"IoU: {IoU}")